---
title: "分類（練習）"
output: html_document
---

```{r, message=FALSE}
library(tidyverse)
library(caret)
```

## 例題：タイタニック（その2）

```{r, eval=FALSE}
install.packages("titanic")
```

データについての説明：https://www.kaggle.com/c/titanic/data

### データの確認

```{r}
my_train <- titanic::titanic_train
my_test <- titanic::titanic_test
```

```{r}
str(my_train)
```

Survivedがint（整数）になっているから，factorに変換する。

```{r}
my_train$Survived <- factor(my_train$Survived)
```

### 欠損値の処理

```{r,warning=FALSE}
psych::describe(my_train)
```

Ageに欠損値がたくさんある。

```{r,warning=FALSE}
psych::describe(my_test)
```

Fareに欠損値がある。

AgeやFareが重要でないなら無視してもいい。とりあえず，ランダムフォレストを試し，変数の重要度を確認する。`na.action = na.omit`で欠損値のあるデータを無視する。

```{r, cache=TRUE}
my_result <- train(form = Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare, data = my_train, na.action = na.omit, method = 'rf')
my_result$finalModel$importance
```

AgeやFareは無視できないことがわかる。

Fareが欠損しているのはテストの1件だけ。中央値で代替する。

```{r}
my_fare <- median(na.omit(c(my_train$Fare, my_test$Fare)))
my_test$Fare[is.na(my_test$Fare)] <- my_fare
```

Ageが欠損しているところはたくさんあるが，それらも中央値で代替する。

```{r}
my_age <- median(na.omit(c(my_train$Age, my_test$Age)))
my_train$Age[is.na(my_train$Age)] <- my_age
my_test$Age[is.na(my_test$Age)] <- my_age
```

### 訓練

```{r, cache=TRUE}
my_result <- train(form = Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare, data = my_train, method = 'knn')
```

訓練データの再現

```{r}
my_train_prediction <- predict(object = my_result, newdata = my_train)
confusionMatrix(data = my_train_prediction, reference = my_train$Survived, positive = "1")
```

### テスト

```{r}
my_test_prediction <- predict(object = my_result, newdata = my_test)
```

正解はわからないから，混同行列は作れない。

```{r}
my_prediction <- data.frame(PassengerId = my_test$PassengerId, Survived = my_test_prediction)
head(my_prediction)
```

これをファイルに保存する。

```{r}
write_csv(x = my_prediction, path = 'titanic-prediction.csv')
```

**練習：** titanic-prediction.csvをExcel（またはテキストエディタ）で開いて，結果を確認せよ。

## 例題：クレジットカードの不払い情報

```{r}
library(ISLR)
my_data <- Default
head(my_data)
```

**練習：** defaultを出力変数，studentを入力変数として，ロジスティック回帰を実行し，結果を確認せよ。ここでは，すべてのデータを訓練データとして使ってよい。ヒント：`train()`の引数を`method = "glm", family = binomial()`とする．

**練習：** defaultを出力変数，それ以外を入力変数として，ロジスティック回帰を実行し，結果を確認せよ。ここでは，すべてのデータを訓練データとして使ってよい。

**練習：** K最近傍法，ロジスティック回帰，決定木におけるROC曲線を描き，AUCを求めよ。ここでは，すべてのデータを訓練データとして使ってよい。

**レポート課題11：データマイニングのコンペをしているサイト，[Kaggle](https://www.kaggle.com/)のアカウントを作り，[Titanic](https://www.kaggle.com/c/titanic)に挑戦してみましょう。レポートには，挑戦した証拠を掲載してください。講義資料ではK最近傍法を使っていますが，別の手法の方が性能がいいかもしれません。**